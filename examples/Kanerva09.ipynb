{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Following along with [Kanerva 2009](http://ww.robertdick.org/iesr/papers/kanerva09jan.pdf), starting from \"Hyperdimensional Representation\". Please do open these side-by-side, while there is quite a bit of text copied over, it's mostly formulas, where as the interesting insights can only be found in the paper.\n",
    "\n",
    "Also the booleans {0, 1} are used instead of {-1, 1}."
   ],
   "metadata": {
    "id": "NOI12OqGdn8N"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vbMqBxsjb-bb",
    "outputId": "4d398beb-3e46-46f5-d480-41aa9623201f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: bhv==0.2.1 in /usr/local/lib/python3.9/dist-packages (0.2.1)\n"
     ]
    }
   ],
   "source": [
    "# Let's install the package\n",
    "!pip install numpy\n",
    "!pip install bhv==0.3.1"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Hypervectors here are called Boolean-Hyper-Vectors or BHVs for short.\n",
    "# Import our favorite BHV implementation (where 64 bits are packed into words), NumpPy!\n",
    "from bhv.np import NumPyPacked64BHV as BHV\n",
    "# Import the correspondings permutation datastructure, we'll get to this\n",
    "from bhv.np import NumPyWordPermutation as Perm"
   ],
   "metadata": {
    "id": "EDIUuPFxcE86"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "> We can measure distances between points in Euclidean\n",
    "or Hamming metric. For binary spaces the Hamming distance is the simplest: it is the number of places at which\n",
    "two binary vectors differ, and it is also the length of the\n",
    "shortest path from one corner point to the other along the\n",
    "edges of the hypercube. In fact, there are 2k such shortest\n",
    "paths between two points that are k bits apart. Naturally,\n",
    "the maximum Hamming distance is 10,000 bits, from any\n",
    "point to its opposite point.\n",
    "\n",
    "One example of opposite points is 101010... and 010101... which differs in every position.\n",
    "The example of opposite points below is all zeros and all ones.\n",
    "The absolute distance in number of bits can be retrieved by `hamming`."
   ],
   "metadata": {
    "id": "v-NUzO0xeFvN"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(BHV.ONE.hamming(BHV.ZERO))\n",
    "# Note that the hypervector dimension here is 8192 instead of 10000"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bgf3SLs9dizu",
    "outputId": "db00a9b5-8415-4b36-fad7-b0c3f9c1aa74"
   },
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8192\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> Although the points are not concentrated or clustered\n",
    "anywhere in the space—because every point is just like\n",
    "every other point—the distances are highly concentrated\n",
    "half-way into the space, or around the distance of 5,000\n",
    "bits, or 0.5.\n",
    "\n",
    "Let's generate two random BHVs and find their bit-error-rate (BER), this should be close to 0.5. The BER corresponds to the hamming distance over the number of dimensions. `rand`"
   ],
   "metadata": {
    "id": "kwmGGW0Sea6_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(BHV.rand().bit_error_rate(BHV.rand()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cQl-HTaBeaPQ",
    "outputId": "9f301e72-7820-4ba3-ad42-86f364acf1b8"
   },
   "execution_count": 8,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.4986572265625\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> It is easy to see that half the space is closer to a\n",
    "point than 0.5 and the other half is further away, but it is\n",
    "somewhat surprising that less than a millionth of the space\n",
    "is closer than 0.476 and less than a thousand-millionth is\n",
    "closer than 0.47; similarly, less than a millionth is further\n",
    "than 0.524 away and less than a thousand-millionth is\n",
    "further than 0.53. These figures are based on the binomial\n",
    "distribution with mean 5,000 and standard deviation (STD)\n",
    "50, and on its approximation with the normal distribution—\n",
    "the distance from any point of the space to a randomly\n",
    "drawn point follows the binomial distribution. \n",
    "\n",
    "This is a useful notion, and how likely a BHV is to occur randomly generated,\n",
    "can be found by `zscore` (giving you the standard deviations) \n",
    "and `pvalue` (the absolute chance). \n"
   ],
   "metadata": {
    "id": "tUVOmrMkeg1S"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# very likely to be randomly generated, because it is\n",
    "# Here -1.0 would mean \"one standard deviation less 1s than expected\"\n",
    "print(BHV.rand().zscore())\n",
    "# flipping just 5% extra on, makes it a 6 sigma+ outlier\n",
    "print(BHV.rand().flip_frac_on(0.05).zscore())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NILBbwFyelYM",
    "outputId": "461f72e7-75a0-440d-c7fd-c8da26e51b1b"
   },
   "execution_count": 9,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "-1.524698996933493\n",
      "9.081902720864719\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> We can go on\n",
    "taking vectors at random without needing to worry about\n",
    "running out of vectors—we run out of time before we run\n",
    "out of vectors. We say that such vectors are unrelated.\n",
    "\n",
    "All vectors we'll practically sample are all unrelated.\n",
    "There's a `related` function that takes the safety margin, 6 sigma by default."
   ],
   "metadata": {
    "id": "G6T26CZReniU"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "random_bhvs = BHV.nrand(10)\n",
    "for x in random_bhvs:\n",
    "    for y in random_bhvs:\n",
    "        if x != y:\n",
    "            assert x.unrelated(y)"
   ],
   "metadata": {
    "id": "-hKvZecoesTt"
   },
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> Measured in standard deviations, the bulk of the space, and\n",
    "the unrelated vectors, are 100 STDs away from any given\n",
    "vector.\n",
    "\n",
    "So we expect two BHVs in the space to be 100 (or in our case, 90) STDs apart."
   ],
   "metadata": {
    "id": "umz_8fW_euM0"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "print(BHV.rand().std_apart(BHV.rand()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1lisENMeyZM",
    "outputId": "5c6dfc6e-05cc-496b-d2be-c2466e653c81"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "91.03999807776799\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> This peculiar distribution of the space makes hyperdimensional representation robust. When meaningful entities\n",
    "are represented by 10,000-bit vectors, many of the bits can\n",
    "be changed—more than a third—by natural variation in\n",
    "stimulus and by random errors and noise, and the resulting\n",
    "vector can still be identified with the correct one, in that it\n",
    "is closer to the original ‘‘error-free’’ vector than to any\n",
    "unrelated vector chosen so far, with near certainty.\n",
    "\n",
    "Let's try and flip 1/3 bits, and see how many STDs they are apart.\n",
    "This is a lot less than the previous test!"
   ],
   "metadata": {
    "id": "_ouRqEBOe3V_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "r = BHV.rand()\n",
    "\n",
    "print(r.std_apart(r.flip_frac(1/3)))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Eae583Yfe7lW",
    "outputId": "c0d07ba6-0ffc-48e9-9de6-402c06f5e7d8"
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "59.021319142164636\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> The robustness is illustrated further by the following\n",
    "example. Let us assume that two meaningful vectors A and\n",
    "B are only 2,500 bits apart—when only 1/4 of their bits\n",
    "differ. The probability of this happening by chance is about\n",
    "zero, but a system can create such vectors when their\n",
    "meanings are related; more on such relations will be said\n",
    "later. So let us assume that 1/3 of the bits of A are changed\n",
    "at random; will the resulting ‘‘noisy’’ A vector be closer to\n",
    "B than to A—would it be falsely identified with B? It is\n",
    "possible but most unlikely because the noisy vector would\n",
    "be 4,166 bits away from B, on the average, and only 3,333\n",
    "bits from A; the difference is 17 STDs. The (relative)\n",
    "distance from the noisy A vector to B is given by d = e -\n",
    "2de with d = 1/4 and e = 1/3. Thus, adding e amount of\n",
    "noise to the first vector increases the distance to the second\n",
    "vector by (1 - 2d)e on the average. Intuitively, most\n",
    "directions that are away from A in hyperspace are also\n",
    "away from B.\n",
    "\n",
    "Let's follow the full example.\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "zMYkc4hFfELA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A = BHV.rand()\n",
    "A_corrupted = A.flip_frac(1/3)\n",
    "B = A.flip_frac(1/4)\n",
    "\n",
    "d = 1/4\n",
    "e = 1/3\n",
    "relative_distance = d + e - 2*d*e\n",
    "\n",
    "print(relative_distance)\n",
    "print(A_corrupted.bit_error_rate(B))\n",
    "\n",
    "# Note this is not the 17 STDs from the paper because we're working in less dimensions\n",
    "print(A_corrupted.std_apart(B) - A.std_apart(A_corrupted))\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XSoOhsiifHaC",
    "outputId": "3bd2ac7b-fcbd-4a77-df21-a458ce069597"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.41666666666666663\n",
      "0.4180908203125\n",
      "14.871339491829573\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> The similarity of patterns is the flip-side of distance. We\n",
    "say that two patterns, vectors, points are similar to each\n",
    "other when the distance between them is considerably\n",
    "smaller than 0.5. We can now describe points of the space\n",
    "and their neighborhoods as follows. Each point has a large\n",
    "‘‘private’’ neighborhood in terms of distance: the volume of\n",
    "space within, say, 1/3 or 3,333 bits is insignificant compared to the total space. The rest of the space—all the\n",
    "unrelated ‘‘stuff’’—becomes significant only when the\n",
    "distance approaches 0.5. In a certain probabilistic sense,\n",
    "then, two points even as far as 0.45 apart are very close to\n",
    "each other. Furthermore, the ‘‘private’’ neighborhoods of\n",
    "any two unrelated points have points in common—there\n",
    "are patterns that are closely related to any two unrelated\n",
    "patterns. For example, a point C half-way between unrelated points A and B is very closely related to both, and\n",
    "another half-way point D can be unrelated to the first, C.\n",
    "This can be shown with as few as four dimensions:\n",
    "A = 0000, B = 0011, C = 0001, and D = 0010. However, the ‘‘unusual’’ probabilities implied by these relative\n",
    "distances require high dimensionality. This is significant\n",
    "when representing objects and concepts with points of the\n",
    "hyperspace, and significantly different from what we are\n",
    "accustomed to in ordinary three-dimensional space.\n",
    "\n",
    "Let's do the same experiment (with BHVs) and verify for ourselves that while both C and D are at a halfwaypoint, they're further removed from each other than from A B.\n",
    "\n"
   ],
   "metadata": {
    "id": "4ZmIN-AjDol7"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A = BHV.ZERO\n",
    "B = BHV.ONE\n",
    "C = BHV.rand() # random is halfway between 0 and 1 on average\n",
    "D = ~C # the inverse of C is unrelated to C\n",
    "\n",
    "print(A.bit_error_rate(C), B.bit_error_rate(C))\n",
    "print(A.bit_error_rate(D), B.bit_error_rate(D))\n",
    "print(C.bit_error_rate(D))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zH6sbjZWEPnR",
    "outputId": "39416e2c-c8bc-4a7a-ec4c-23e3519b37b9"
   },
   "execution_count": 14,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.50146484375 0.49853515625\n",
      "0.49853515625 0.50146484375\n",
      "1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> The sum (and the mean) of random vectors has the\n",
    "following important property: it is similar to each of the\n",
    "vectors being added together. The similarity is very pronounced when only a few vectors are added\n",
    "\n",
    "We're working with BHVs so we don't have a sum with the same properties, but there is a notion of mean. The mean is a \"majority\" operation plus a tiebreaker for even numbers of BHVs."
   ],
   "metadata": {
    "id": "kGVmlgLUFVwz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vs = BHV.nrand(5)\n",
    "vs_mean = BHV.majority(vs)\n",
    "\n",
    "# while the random vectors are pairwise unrelated\n",
    "for i in range(5):\n",
    "    assert vs[i].unrelated(vs[(i + 1) % 5])\n",
    "# they're all related to the mean\n",
    "print(vs[0].bit_error_rate(vs_mean))\n",
    "print(vs[0].std_apart(vs_mean))\n",
    "\n",
    "#for v in vs:\n",
    "#    assert v.sixsigma(vs_mean)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_UQaN-iYHK7N",
    "outputId": "7d997c22-b28d-40bb-9ac8-0b4f05b677da"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3062744140625\n",
      "55.44159106240774\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> A very basic and simple multiplication of binary vectors is\n",
    "by componentwise Exclusive-Or (XOR). The XOR of two vectors has 0s where the two agree and it has 1s where they\n",
    "disagree. For example, 0011…10 XOR 0101…00 =\n",
    "0110…10. Mathematically, the XOR is the arithmetic sum\n",
    "modulo 2. The (1, -1)-binary system, also called bipolar,\n",
    "is equivalent to the (0, 1)-binary system when the XOR is\n",
    "replaced by ordinary multiplication. We will use the\n",
    "notation A  B for the multiplication of the vectors A and\n",
    "B—for their product-vector. Here * is the XOR unless\n",
    "otherwise noted.\n",
    "The XOR commutes, A \\* B = B \\* A, and is its own\n",
    "inverse so that A \\* A = O, where O is the vector of all 0s\n",
    "(in algebra terms O is the unit vector because A \\* O \\= A).\n",
    "\n",
    "Here we'll denote XOR with the carret `^`. The laws are thoroughly tested in the library, but let's look at a few examples here."
   ],
   "metadata": {
    "id": "NlBBUHpfJSUK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A = BHV.rand()\n",
    "B = BHV.rand()\n",
    "\n",
    "# commutative\n",
    "assert A ^ B == B ^ A\n",
    "# it's own inverse\n",
    "assert A ^ A == BHV.ZERO"
   ],
   "metadata": {
    "id": "oN0wmBc_KGPL"
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> Since the XOR-vector has 1s where the two vectors disagree, the number of 1s in it is the Hamming distance\n",
    "between the two vectors. By denoting the number of 1s in a\n",
    "binary vector X with |X| we can write the Hamming distance d between A and B as d(A, B) = |A * B|\n",
    "\n",
    "Here we'll refrain from choosing a standard distance metric, but this fact is used everywere."
   ],
   "metadata": {
    "id": "mSm0fKN5Kgeb"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A = BHV.rand()\n",
    "B = BHV.rand()\n",
    "\n",
    "assert A.hamming(B) == (A ^ B).active()"
   ],
   "metadata": {
    "id": "lmMEgrEXK8_B"
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> Multiplication can be thought of as a mapping of points\n",
    "in the space. Multiplying the vector X with A maps it to\n",
    "the vector X_A = A \\* X which is as far from X as there are 1s\n",
    "in A (i.e., d(A, X) = |X_A \\* X| = |(A \\* X) \\* X| = |A \\* X \\* X| = |A|).\n",
    "\n",
    "Another few important properties, set out in code."
   ],
   "metadata": {
    "id": "HifVlSIWLLZD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A = BHV.rand()\n",
    "X = BHV.rand()\n",
    "\n",
    "X_A = A ^ X\n",
    "\n",
    "assert X_A.hamming(X) == A.active()"
   ],
   "metadata": {
    "id": "azWR7sYsL4ZQ"
   },
   "execution_count": 18,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> If A is a typical (random) vector of the space,\n",
    "about half of its bits are 1s, and so X_A is in the part of the\n",
    "space that is unrelated to X in terms of the distance criterion. Thus we can say that multiplication randomizes.\n",
    "\n",
    "Let's check this "
   ],
   "metadata": {
    "id": "j4NuP4_uMN4Y"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A = BHV.rand()\n",
    "X = BHV.rand()\n",
    "\n",
    "X_A = A ^ X\n",
    "\n",
    "print(X_A.std_apart(X))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1ECoTK2M1Mb",
    "outputId": "c0552d07-0f04-4115-86b1-6495ab2957c7"
   },
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "89.44900782009826\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> Mapping with multiplication preserves distance. This is\n",
    "seen readily by considering X_A = A \\* X and Y_A = A \\* Y;\n",
    "taking their XOR, and noting that the two As cancel out\n",
    "thus: X_A \\* Y_A = (A \\* X) \\* (A \\* Y) = A \\* X \\* A \\* Y = X \\* Y\n",
    "Since the XOR-vector is the same, the Hamming distance\n",
    "is the same: |X_A \\* Y_A| = |X \\* Y|\n",
    "\n",
    "And the logical extension"
   ],
   "metadata": {
    "id": "6suk74j-NG9I"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A = BHV.rand()\n",
    "X = BHV.rand()\n",
    "Y = BHV.rand()\n",
    "\n",
    "X_A = A ^ X\n",
    "Y_A = A ^ Y\n",
    "\n",
    "assert (X_A ^ Y_A) == X ^ Y"
   ],
   "metadata": {
    "id": "OFT0isDkNBal"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> A very useful property of multiplication is that it\n",
    "distributes over addition. That means, for example, that\n",
    "A \\* \\[X + Y + Z\\] = \\[A \\* X + A \\* Y + A \\* Z\\]\n",
    "The brackets \\[…\\] stand for normalization. Distributivity is\n",
    "invaluable in analyzing these representations and in\n",
    "understanding how they work and fail.\n",
    "\n",
    "The BHVs do not support normalization in the sense that's meant here. Therefore, care has to be taken as to not introduce unwanted noise. Instead of adding multiple times, and normalizing, one should prefer the addition (here mean) of multiple items."
   ],
   "metadata": {
    "id": "tev_H6MyOm25"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "A, X, Y, Z = BHV.nrand(4)\n",
    "\n",
    "LHS = A ^ BHV.majority([X, Y, Z])\n",
    "RHS = BHV.majority([A ^ X, A ^ Y, A ^ Z])\n",
    "\n",
    "assert LHS == RHS"
   ],
   "metadata": {
    "id": "LKNxJExVPdL_"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> Permutations reorder the vector components and thus are\n",
    "very simple; they are also very useful in constructing a\n",
    "cognitive code. We will denote the permutation of a vector\n",
    "with a multiplication by a matrix (the permutation matrix\n",
    "Π), thus X_Π = ΠX. We can also describe the permutation\n",
    "of n elements as the list of the integers 1, 2, 3, …, n in the\n",
    "permuted order. A random permutation is then one where\n",
    "the order of the list is random—it is a permutation chosen\n",
    "randomly from the n! possible permutations.\n",
    "\n",
    "When theory hits reality, it's not quite as pretty. Firstly, a 8192x8192 matrix is large (LA folks are laughing in the background) and wasteful. This can be resolved by using a denser representation (`NumPyWordPermutation` uses an array of indices, which is [still no optimal](https://hackmd.io/@dabo/rkP8Pcf9t#A-compact-data-structure-for-storing-a-permutation)). Secondly, the number of permutations 8192! is extremely large (28000+ digits). Therefore, implementions needn't support all permutations (`NumPyWordPermutation` only supports permutations on 64 bit words at the moment). Let's take a look at the basic properties with an explicit representation.\n"
   ],
   "metadata": {
    "id": "41j5JCzkP5cV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Π = Perm.random()\n",
    "\n",
    "X, Y = BHV.nrand(2)\n",
    "\n",
    "assert Π(X) ^ Π(Y) == Π(X ^ Y)\n",
    "assert Π(X).hamming(Π(Y)) == X.hamming(Y)"
   ],
   "metadata": {
    "id": "b2L1NO9pHEvq"
   },
   "execution_count": 22,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "> As mentioned above, we can map the same vector with two\n",
    "different permutations and ask how similar the resulting\n",
    "vectors are: by permuting X with Π and Γ, what is the\n",
    "distance between ΠX and ΓX (...)? Unlike above with multiplication by\n",
    "a vector, this depends on the vector X (e.g., the 0-vector is\n",
    "unaffected by permutation).\n",
    "\n",
    "Let's generate another permutation."
   ],
   "metadata": {
    "id": "LsrVrNSmhD38"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "Π, Γ = Perm.nrandom(2)\n",
    "\n",
    "X = BHV.rand()\n",
    "\n",
    "assert Π(X).unrelated(Γ(X))"
   ],
   "metadata": {
    "id": "wIn3BSTHiC0s"
   },
   "execution_count": 23,
   "outputs": []
  }
 ]
}
